{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8b77e93177d15389368c3b9a1756bc0d\", element=\"86b88088-f7c4-4ba2-b233-317e0b447e26\")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc = driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the title names\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "for in in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the company names\n",
    "companies_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all tags having the experience required data\n",
    "experience_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_list=[]\n",
    "for i in experience_tags:\n",
    "       experience_list.append(i.text)\n",
    "experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_titles),len(companyy_names),len(experience_list),len(locations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data from job openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_opening_urls = []\n",
    "\n",
    "url = driver.find_elemets_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in url:\n",
    "       job_opening_urls.append(i.get_attribute('href'))\n",
    "job_openings_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "for i in job_opening_urls:\n",
    "       driver.get(i)\n",
    "        try:\n",
    "            job_title = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            job_titles.append(job_title.text)\n",
    "    except:\n",
    "        pass\n",
    "    job_titles\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "    next_button = driver.find_element_by_xpath(\"//span[@class='fw500 fleft']\")\n",
    "    next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc = driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "for in in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the company names\n",
    "companies_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_titles),len(company_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data from job openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_opening_urls = []\n",
    "\n",
    "url = driver.find_elemets_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in url:\n",
    "       job_opening_urls.append(i.get_attribute('href'))\n",
    "job_openings_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "for i in job_opening_urls:\n",
    "       driver.get(i)\n",
    "        try:\n",
    "            job_title = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            job_titles.append(job_title.text)\n",
    "    except:\n",
    "        pass\n",
    "    job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "    next_button = driver.find_element_by_xpath(\"//span[@class='fw500 fleft']\")\n",
    "    next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the \n",
    "webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \" pip install selenium \"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Update the URL of Naukri Page! ( Make Sure that the page link which you're putting must be a job listing page and it must have Next page buttons. )\n",
    "driver.get(\"https://www.naukri.com/jobs-in-Delhi-NCR-1\")\n",
    "\n",
    "count = 1000  # Update the Number of Vacancy count you want to scrape.\n",
    "\n",
    "index, new_index, i = '0', 1, 0  # This the the index variable of the elements from which data will be Scraped\n",
    "# Xpaths of the various element from which data will be scraped.\n",
    "heading_xpath = '(//*[@class=\"jobTuple bgWhite br4 mb-8\"])['+index+']/div/div/a'\n",
    "link_xpath = '(//*[@class=\"jobTuple bgWhite br4 mb-8\"])['+index+']/div/div/a'\n",
    "subheading_xpath = '(//*[@class=\"jobTuple bgWhite br4 mb-8\"])['+index+']/div/div/div/a'\n",
    "experience_xpath = '(//*[@class=\"jobTuple bgWhite br4 mb-8\"])['+index+']/div/div/ul/li[1]/span'\n",
    "salary_xpath = '(//*[@class=\"jobTuple bgWhite br4 mb-8\"])['+index+']/div/div/ul/li[2]/span'\n",
    "\n",
    "csv_file = open('Naukri_scrape.csv', 'a', encoding=\"utf-8\", newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "# Writing the Heading of CSV file.\n",
    "csv_writer.writerow(['Heading', 'Sub Heading', 'Vacancy Link', 'Experience Needed', 'Salary'])\n",
    "\n",
    "while i < count:\n",
    "\n",
    "    for j in range(20):\n",
    "        # Here we're replacing the Old index count of Xpath with New Index count.\n",
    "        temp_index = str(new_index).zfill(2)  # Zfill(2) is used to put zeros to the left of any digit till 2 decimal places.\n",
    "        heading_xpath = heading_xpath.replace(index, temp_index)\n",
    "        link_xpath = link_xpath.replace(index, temp_index)\n",
    "        subheading_xpath = subheading_xpath.replace(index, temp_index)\n",
    "        experience_xpath = experience_xpath.replace(index, temp_index)\n",
    "        salary_xpath = salary_xpath.replace(index, temp_index)\n",
    "        index = str(new_index).zfill(2)\n",
    "        try:\n",
    "            # Capturing the Heading from webpage and storing that into Heading variable.\n",
    "            heading = wait.until(EC.presence_of_element_located((By.XPATH, heading_xpath))).text\n",
    "            print(heading)\n",
    "        except:\n",
    "            heading = \"NULL\"\n",
    "        try:\n",
    "            link = wait.until(EC.presence_of_element_located((By.XPATH, link_xpath))).get_attribute('href')\n",
    "            print(link)\n",
    "        except:\n",
    "            link = \"NULL\"\n",
    "        try:\n",
    "            subheading = wait.until(EC.presence_of_element_located((By.XPATH, subheading_xpath))).text\n",
    "            print(subheading)\n",
    "        except:\n",
    "            subheading = \"NULL\"\n",
    "        try:\n",
    "            experience = wait.until(EC.presence_of_element_located((By.XPATH, experience_xpath))).text\n",
    "            print(experience)\n",
    "        except:\n",
    "            experience = \"NULL\"\n",
    "        try:\n",
    "            salary = wait.until(EC.presence_of_element_located((By.XPATH, salary_xpath))).text\n",
    "            print(salary)\n",
    "        except:\n",
    "            salary = \"Not Disclosed\"\n",
    "        new_index += 1\n",
    "        i += 1\n",
    "        print(\"--------------------------- \"+str(i)+\" ----------------------------------\")\n",
    "        # Writing all the Scrapped data into CSV file.\n",
    "        csv_writer.writerow([heading, subheading, link, experience, salary])\n",
    "        if i >= count:\n",
    "            break\n",
    "    if i >= count:\n",
    "        break\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//*[text() = \"Next\"]'))).click()\n",
    "    new_index = 1\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist \n",
    "Designation in Noida location. You have to scrape company_name, No. of days \n",
    "ago when job was posted, Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc = driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the title names\n",
    "title_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "titles_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the company names\n",
    "company_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_titles),len(company_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data from job openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_opening_urls = []\n",
    "\n",
    "url = driver.find_elemets_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in url:\n",
    "       job_opening_urls.append(i.get_attribute('href'))\n",
    "job_openings_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "for i in job_opening_urls:\n",
    "       driver.get(i)\n",
    "        try:\n",
    "            job_title = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            job_titles.append(job_title.text)\n",
    "    except:\n",
    "        pass\n",
    "    job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "    next_button = driver.find_element_by_xpath(\"//span[@class='fw500 fleft']\")\n",
    "    next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation \n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/salaries/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc = driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the title names\n",
    "title_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "titles_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets extract all tags having the company names\n",
    "company_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_locations=[]\n",
    "for i in location_tags:\n",
    "    job_locations.append(i.text)\n",
    "job_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "salaries_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_salaries=[]\n",
    "for i in salary_tags:\n",
    "    job_salaries.append(i.text)\n",
    "job_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings_tags=driver.find_elementd_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span]\")\n",
    "Ratings_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_Ratings=[]\n",
    "for i in rating_tags:\n",
    "    job_Ratings.append(i.text)\n",
    "job_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print Min salary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print Max Salary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average salary = Min salary + Max Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_titles),len(company_names),len(min_salaries),len(max_salaries),len(Average_salary), [\"//a, Ratings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names\n",
    "jobs['salary']=Average_salaries\n",
    "jobs['ratings']=Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data from job openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_opening_urls = []\n",
    "\n",
    "url = driver.find_elemets_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in url:\n",
    "       job_opening_urls.append(i.get_attribute('href'))\n",
    "job_openings_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "for i in job_opening_urls:\n",
    "       driver.get(i)\n",
    "        try:\n",
    "            job_title = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            job_titles.append(job_title.text)\n",
    "    except:\n",
    "        pass\n",
    "    job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "    next_button = driver.find_element_by_xpath(\"//span[@class='fw500 fleft']\")\n",
    "    next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to \n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_Product = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_Product.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_Brand = driver.find_element_by_id('qsb-Brand-sugg')\n",
    "search_Brand.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using class_name function\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "Price_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discount_tags=driver.find_elementd_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "Discount_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "Product=pd.DataFrame({})\n",
    "Product['Description']=Product_Description\n",
    "Product['Brand']=Product_Brand\n",
    "Product['Price']=Product_Price\n",
    "Product['Discount']=Product_Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "    next_button = driver.find_element_by_xpath(\"//span[@class='fw500 fleft']\")\n",
    "    next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
